# -*- coding: utf-8 -*-
"""cmp9139_usamaahmed_29523887.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z4kWpv0AqGvfwyOvvrL8301zfVKvbNtL
"""

pip install numpy==1.26.4 scipy==1.11.4 pymc arviz

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

# Define your dataset folder path dynamically
base_path = '/content/drive/MyDrive/Ahmed/'

"""**Step 1 – Import Required Libraries**"""

# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

"""**Step 2 – Load Dataset Dynamically**

"""

from pathlib import Path
import pandas as pd

# Paths
data_file = list(Path(base_path).glob('adult.data'))[0]
names_file = list(Path(base_path).glob('adult.names'))[0]

# Load dataset
df = pd.read_csv(data_file, header=None, na_values='?', skipinitialspace=True)

# Manually specify correct column names (official UCI names)
col_names = [
    'age', 'workclass', 'fnlwgt', 'education', 'education-num',
    'marital-status', 'occupation', 'relationship', 'race', 'sex',
    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'
]
df.columns = col_names + ['income']  # target column

print("Shape:", df.shape)
df.head()

"""**Step 3 – Dataset Overview (Appendix Table A1)**

"""

info_df = pd.DataFrame({
    "Attribute": df.columns,
    "Data Type": df.dtypes.values,
    "Non-Null Count": df.notnull().sum().values
})
info_df

"""**Step 4 – Missing Data Summary (Appendix Table A2)**"""

missing_summary = df.isnull().sum().reset_index()
missing_summary.columns = ["Attribute", "Missing_Values"]
missing_summary['Missing_Percent'] = (missing_summary['Missing_Values'] / len(df)) * 100
missing_summary

"""**Step 5: Data Cleaning**"""

# Clean missing rows
df_clean = df.dropna()

# Strip spaces from string columns
for col in df_clean.select_dtypes(include='object').columns:
    df_clean[col] = df_clean[col].str.strip()

df_clean.info()

"""### **Appendix Phase 2 – Descriptive Statistics & Visualizations**

Step 1 – Generate Descriptive Statistics (Table A3)
**bold text**
"""

# Descriptive statistics for numerical columns
desc_stats = df.describe().T
desc_stats = desc_stats[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]
desc_stats.reset_index(inplace=True)
desc_stats.rename(columns={'index': 'Attribute'}, inplace=True)

desc_stats

"""**Step 2 – Frequency Counts for Key Categorical Variables (Table A4)**

"""

# Frequency table for categorical columns
categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']

freq_tables = {}
for col in categorical_cols:
    freq_tables[col] = df[col].value_counts().reset_index()
    freq_tables[col].columns = [col, 'Count']

# Example output for 'sex'
freq_tables['sex']

"""**Step 3 – Visualize Gender Distribution**"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
sns.countplot(data=df, x='sex', palette='Set2')
plt.title('Gender Distribution')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.show()

"""Step 4 – Visualize Income Distribution
**bold text**
"""

plt.figure(figsize=(6,4))
sns.countplot(data=df, x='income', palette='Set1')
plt.title('Income Distribution')
plt.xlabel('Income Category')
plt.ylabel('Count')
plt.show()

"""Step 5 – Cross-tab Gender vs Income (For Hypothesis 1)
**bold text**
"""

gender_income_table = pd.crosstab(df['sex'], df['income'])
gender_income_table

"""# Appendix Phase 3 – Exploratory Visualizations

Step 1 – Set Visualization Style (IEEE-friendly)
**bold text**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Global style settings
sns.set_theme(style="whitegrid", palette="Blues_d")
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['figure.figsize'] = (7, 5)
plt.rcParams['font.family'] = "sans-serif"
plt.rcParams['font.size'] = 11

"""**Step 2 – Histograms for Key Numeric Attributes**

"""

numeric_cols = ['age', 'hours-per-week', 'capital-gain', 'capital-loss']

for col in numeric_cols:
    plt.figure()
    sns.histplot(df[col], bins=30, kde=True, color='steelblue')
    plt.title(f'Distribution of {col.capitalize()}')
    plt.xlabel(col.capitalize())
    plt.ylabel('Frequency')
    plt.tight_layout()
    plt.show()

"""Figures A3-A6: Histograms for numeric attributes (Age, Hours/week, Capital Gain, Capital Loss).



---

Step 3 – Boxplots for Age vs Income
"""

plt.figure()
sns.boxplot(data=df, x='income', y='age', palette='Blues')
plt.title('Age Distribution by Income Category')
plt.xlabel('Income')
plt.ylabel('Age')
plt.tight_layout()
plt.show()

"""Step 4 – Boxplot for Hours-per-week vs Income
**bold text**
"""

plt.figure()
sns.boxplot(data=df, x='income', y='hours-per-week', palette='Blues')
plt.title('Hours Worked per Week by Income Category')
plt.xlabel('Income')
plt.ylabel('Hours per Week')
plt.tight_layout()
plt.show()

"""Step 5 – Correlation Heatmap for Numeric Features
**bold text**
"""

plt.figure()
corr = df[numeric_cols].corr()
sns.heatmap(corr, annot=True, cmap='Blues', fmt=".2f", cbar=True)
plt.title('Correlation Heatmap of Numeric Features')
plt.tight_layout()
plt.show()

"""Step 6 – Stacked Bar Plot: Education Level vs Income
**bold text**
"""

edu_income = pd.crosstab(df['education'], df['income'], normalize='index')*100
edu_income.plot(kind='bar', stacked=True, figsize=(10,5), color=['lightblue', 'steelblue'])

plt.title('Income Percentage by Education Level')
plt.xlabel('Education Level')
plt.ylabel('Percentage (%)')
plt.legend(title='Income', loc='upper right')
plt.tight_layout()
plt.show()

"""**Appendix Phase 4 – Hypotheses Testing (Inferential Statistics)**

**Step 1 – Hypothesis 1: Gender vs Income (Chi-square Test)**
"""

from scipy.stats import chi2_contingency

# Contingency table
gender_income_ct = pd.crosstab(df['sex'], df['income'])

# Chi-square test
chi2, p, dof, expected = chi2_contingency(gender_income_ct)

# Store results in a table
chi_results = pd.DataFrame({
    'Chi-square Statistic': [chi2],
    'p-value': [p],
    'Degrees of Freedom': [dof]
})
chi_results

sns.countplot(data=df, x='sex', hue='income', palette='Blues')
plt.title('Gender vs Income Levels')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.legend(title='Income')
plt.tight_layout()
plt.show()

"""**Step 2 – Hypothesis 2: Age Difference by Income Group (T-test)**"""

from scipy.stats import ttest_ind

# Split groups
low_income_age = df[df['income'] == '<=50K']['age']
high_income_age = df[df['income'] == '>50K']['age']

# Independent t-test
t_stat, p_val = ttest_ind(low_income_age, high_income_age, equal_var=False)

t_results = pd.DataFrame({
    'T-statistic': [t_stat],
    'p-value': [p_val],
    'Mean Age <=50K': [low_income_age.mean()],
    'Mean Age >50K': [high_income_age.mean()]
})
t_results

sns.boxplot(data=df, x='income', y='age', palette='Blues')
plt.title('Age Distribution by Income Category')
plt.xlabel('Income')
plt.ylabel('Age')
plt.tight_layout()
plt.show()

"""**Step 3 – Hypothesis 3: Education & Hours Effect on Income (Logistic Regression)**

"""

import statsmodels.api as sm

# Encode target variable
df_lr = df.copy()
df_lr['income'] = df_lr['income'].apply(lambda x: 1 if x=='>50K' else 0)

# Select predictors
X = df_lr[['education-num', 'hours-per-week']]
y = df_lr['income']

# Add constant term
X = sm.add_constant(X)

# Logistic regression model
model = sm.Logit(y, X).fit()
log_results = model.summary2().tables[1]
log_results

# Predicted probabilities
df_lr['predicted_prob'] = model.predict(X)

sns.scatterplot(data=df_lr, x='education-num', y='predicted_prob', hue='hours-per-week', palette='Blues', alpha=0.6)
plt.title('Predicted Probability of High Income by Education Level')
plt.xlabel('Education Level (numeric)')
plt.ylabel('Predicted Probability of >50K Income')
plt.colorbar
plt.tight_layout()
plt.show()

"""# **Appendix Phase 5 – Bayesian Logistic Regression**

**Step 1 – Install and Import PyMC3 (Bayesian Library)**
"""

import pymc as pm
import arviz as az
import matplotlib.pyplot as plt
import numpy as np

print("PyMC installed successfully!")

with pm.Model() as model:
    mu = pm.Normal("mu", mu=0, sigma=1)
    obs = pm.Normal("obs", mu=mu, sigma=1, observed=[1,2,3])
    trace = pm.sample(500, tune=500, chains=2, cores=1, target_accept=0.9)

az.plot_trace(trace)
plt.show()

import scipy.signal as signal
import numpy as np

# Add back the deprecated gaussian function if missing
if not hasattr(signal, "gaussian"):
    def gaussian(M, std):
        n = np.arange(0, M) - (M - 1.0) / 2
        return np.exp(-0.5 * (n / std) ** 2)
    signal.gaussian = gaussian

import pymc as pm
import arviz as az
import matplotlib.pyplot as plt

print("PyMC + ArviZ + tsfresh successfully loaded")

with pm.Model() as model:
    x = pm.Normal("x", mu=0, sigma=1)
    trace = pm.sample(500, tune=500, chains=2, target_accept=0.9)

az.plot_trace(trace)

"""**Step 2 – Prepare Data for Bayesian Analysis**

"""

# Dataset copy
bayes_df = df_lr[['education-num', 'hours-per-week', 'income']]

# Standardize predictors for better model convergence
X_std = (bayes_df[['education-num', 'hours-per-week']] - bayes_df[['education-num', 'hours-per-week']].mean()) / bayes_df[['education-num', 'hours-per-week']].std()
y = bayes_df['income'].values

"""**Step 3 – Define Bayesian Logistic Regression Model**

"""

with pm.Model() as logistic_model:
    # Priors for coefficients
    intercept = pm.Normal('Intercept', mu=0, sigma=10)
    beta_edu = pm.Normal('Beta_Education', mu=0, sigma=10)
    beta_hours = pm.Normal('Beta_Hours', mu=0, sigma=10)

    # Logistic model
    logit_p = intercept + beta_edu * X_std['education-num'] + beta_hours * X_std['hours-per-week']
    p = pm.Deterministic('p', pm.math.sigmoid(logit_p))

    # Likelihood
    observed = pm.Bernoulli('Observed', p=p, observed=y)

    # Sampling
    trace = pm.sample(2000, tune=1000, cores=2, chains=2, target_accept=0.95, random_seed=42)

"""**Step 4 – Posterior Summary Table**"""

summary = az.summary(trace, hdi_prob=0.95)
summary

"""**Step 5 – Plot Posterior Distributions**"""

az.plot_posterior(trace, var_names=['Intercept', 'Beta_Education', 'Beta_Hours'], hdi_prob=0.95, color='steelblue')
plt.suptitle('Posterior Distributions of Bayesian Logistic Regression', fontsize=14)
plt.show()

"""**Step 6 – Plot Predicted Probability**"""

!pip install --upgrade arviz==0.17.1

import os
os.environ["NUMBA_DISABLE_JIT"] = "1"

import arviz as az
import matplotlib.pyplot as plt

az.plot_forest(trace, var_names=['Beta_Education', 'Beta_Hours'], combined=True, hdi_prob=0.95, colors='blue')
plt.title('Effect Sizes with 95% Credible Intervals')
plt.show()

!jupyter nbconvert --ClearMetadataPreprocessor.enabled=True \
--to notebook --output cleaned_notebook.ipynb code_cmp9139_usamaahmed_29523887.ipynb